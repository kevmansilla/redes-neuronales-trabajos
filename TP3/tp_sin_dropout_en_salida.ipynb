{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final - Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Importo las librerias necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import *\n",
    "from clasificador import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal autoencoder convolucional de varias capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importo data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the training data\n",
    "train_set_orig = datasets.FashionMNIST(\n",
    "    'MNIST_data/', download=True, train=True,  transform=transform)\n",
    "valid_set_orig = datasets.FashionMNIST(\n",
    "    'MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    j = torch.randint(len(train_set_orig), size=(1,)).item()\n",
    "    image, label = train_set_orig[j]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(train_set_orig.classes[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo data set personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(train_set_orig)\n",
    "valid_set = CustomDataset(valid_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: red autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, n, p=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Convolucional 1\n",
    "            nn.Conv2d(1, 16, kernel_size=3),  # 1x28x28 -> 16x26x26\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.MaxPool2d(2,2), # 16x26x26 -> 16x13x13\n",
    "            # Convolucional 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3),  # 16x13x13 -> 32x11x11\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.MaxPool2d(2, 2),  # 32x11x11 -> 32x5x5\n",
    "            # Linear\n",
    "            nn.Flatten(),  # 32x5x5 -> 32*5*5\n",
    "            nn.Linear(32*5*5, n),  # fully connected 32*5*5 -> n\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Linear\n",
    "            nn.Linear(n, 32*5*5),  # fully connected n -> 32*5*5\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.Unflatten(1, (32,5,5)),  # 32*5*5 -> 32x5x5\n",
    "            # Convolucional transpose (de la segunda convolucional)\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, output_padding=1),  # 32x5x5 -> 16x13x13\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            # Convolucional transpose (de la primera convolucional)\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, output_padding=1),  # 16x13x13 -> 1x28x28\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo sin entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6)\n",
    "n = 64\n",
    "p = 0.2\n",
    "autoencoder_conv = Autoencoder(n, p)\n",
    "model = autoencoder_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_conv.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_conv.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(x):\n",
    "    return x.unsqueeze(0)  # 28x28 -> 1x28x28\n",
    "\n",
    "\n",
    "def unbatch(x):\n",
    "    return x.squeeze().detach().cpu().numpy()  # 1x28x28 -> 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _ = train_set[0]\n",
    "pred = model(batch(image))\n",
    "print(image.size())\n",
    "print(unbatch(pred).shape)\n",
    "print(pred.size())\n",
    "print(unbatch(pred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miramos que imagene predice el modelo sin entrenar\n",
    "figure = plt.figure()\n",
    "rows, cols = 3, 2\n",
    "i = 0\n",
    "for row in range(1, rows + 1):\n",
    "    j = torch.randint(len(train_set), size=(1,)).item()\n",
    "    i += 1\n",
    "    image, _ = train_set[j]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    if row == 1:\n",
    "        plt.title('Original')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    i += 1\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    if row == 1:\n",
    "        plt.title('Reconstructed')\n",
    "    plt.axis(\"off\")\n",
    "    image_pred = unbatch(model(batch(image)))\n",
    "    plt.imshow(image_pred.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: entrenenado el autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(len(valid_set), size=(3,))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orig = model_generator(\n",
    "    Autoencoder, 64, 0.2, 30, 100, 'Adam', 1e-3, train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_orig, valid_set, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variar algunos parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vario dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop05 = model_generator(\n",
    "    Autoencoder, 64, 0.5, 30, 100, 'Adam', 1e-3, train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_drop05, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_64_drop01 = model_generator(\n",
    "    Autoencoder, 64, 0.1, 30, 100, 'Adam', 1e-3, train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_64_drop01, valid_set, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_256_drop01 = model_generator(\n",
    "    Autoencoder, 256, 0.1, 30, 100, 'Adam', 1e-3, train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_256_drop01, valid_set, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variando optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop01_sgd = model_generator(\n",
    "    Autoencoder, 64, 0.2, 30, 100, 'SGD', 1e-3, train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_drop01_sgd, valid_set, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Definiendo un clasificador convolucional reutilizando el encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Classifier_Conv(nn.Module):\n",
    "    def __init__(self, n, encoder, p=0.2):\n",
    "        super(Classifier_Conv, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Linear\n",
    "            nn.Linear(n, 10),  # fully connected n -> 32*5*5\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clasificador usando el modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier_orig = classifier_generator(\n",
    "    Classifier_Conv, 64, model_orig, 0.2, 30, 100, 'Adam', 1e-3, train_set_orig, valid_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4:\n",
    "\n",
    "## Entrenando solo la capa clasificadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_6 = classifier_generator(Classifier_Conv, 64, model_orig,\n",
    "                                    0.2, 30, 100, 'Adam classifier', 1e-3, train_set_orig, valid_set_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
