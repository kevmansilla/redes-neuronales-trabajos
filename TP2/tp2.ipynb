{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto A\n",
    "Se debe implementar una red feed-forward auto-encoder con una capa oculta $n=64$ para aprender la función identidad con la base de datos Fashion-MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos los conjuntos de datos de entrenamiento y testeo desde la libreria Datasets de torch\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train= True, \n",
    "    download= True, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se toma la subclase creada en los prácticos para poder redimensionar las imagénes y los labels\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)   \n",
    "    def __getitem__(self,i):\n",
    "        image,label=self.dataset[i]\n",
    "        label=torch.flatten(image) # Se reescribe el label original con una version achatada de la imagen dado\n",
    "        # que en este trabajo no estamos clasificando las imagenes, simplemente las estamos reconstruyendo.\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_data)\n",
    "test_dataset = CustomImageDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hiperparámtros\n",
    "batch_size = 1000\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego de descargar los datos ahora es necesario cargarlos especificando el tamaño del batch y con el \n",
    "# parámetro shuffle estamos permitiendo que las muestras sean aleatorias. \n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de los tensores de las imágenes y las etiquetas en el conjunto de entrenamiento\n",
    "train_imag, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_imag.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de los tensores de las imágenes y las etiquetas en el conjunto de testeo\n",
    "test_imag, test_labels = next(iter(test_loader))\n",
    "print(f\"Feature batch shape: {test_imag.size()}\")\n",
    "print(f\"Labels batch shape: {test_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función se utiliza para obtener el dispositivo disponible en mi computadora y para luego \"guardar\" el modelo ahi\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la arquitectura de la red neuronal\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        #encoder\n",
    "        self.enc1 = nn.Linear(in_features=28*28, out_features= n)\n",
    "\n",
    "        #decoder\n",
    "        self.dec1 = nn.Linear(in_features=n, out_features= 28*28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.enc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dec1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64 #Tamaño capa intermedia\n",
    "device = get_device()\n",
    "AE_model = AE().to(device)\n",
    "print(AE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1 #tasa de aprendizaje\n",
    "loss_fn = nn.MSELoss() #función de pérdida\n",
    "optimizer = optim.SGD(AE_model.parameters(), lr = lr) #algoritmo optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se define la función entrenamiento y de testeo \n",
    "train_loss = []\n",
    "test_loss = []\n",
    "def train(dataset):\n",
    "  running_loss = 0\n",
    "  AE_model.train() #modo entrenamiento\n",
    "  for batch, (X,y) in enumerate(dataset): #se itera por batch\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = AE_model(X)\n",
    "    \n",
    "    loss = loss_fn(pred,y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  #Resultados de la función de pérdida, cada resultado se guarda en el vector vacío train_loss    \n",
    "  running_loss /= len(train_loader)\n",
    "  print(\"Train Loss: {}\".format(running_loss))\n",
    "  train_loss.append(running_loss)\n",
    "\n",
    "def test(dataset):\n",
    "  running_test_loss = 0\n",
    "  AE_model.eval() #modo evaluación (o testeo)\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataset:\n",
    "      pred = AE_model(X)\n",
    "\n",
    "      loss = loss_fn(pred, y)\n",
    "\n",
    "      running_test_loss += loss.item()\n",
    "  #Resultados de la función de pérdida, cada resultado se guarda en el vector vacío test_loss  \n",
    "  running_test_loss /= len(dataset)\n",
    "  print(\"Test Loss: {}\".format(running_test_loss))\n",
    "  test_loss.append(running_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrena el modelo por 200 épocas\n",
    "for epoch in range(epochs):\n",
    "  print(\"Época {} de {}\".format(epoch+1, epochs))\n",
    "  train(train_loader)\n",
    "  test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "  \n",
    "# Se extrae el último batch del dataset de testeo \n",
    "img, _ = list(test_loader)[-1]\n",
    "\n",
    "out = AE_model(img) # Se obtiene el output del modelo para este batch, es decir que vamos a ver como \n",
    "# el modelo reconstruye las imágenes \n",
    "  \n",
    "# guardamos en un diccionario la imagen original y la predicha por el modelo\n",
    "outputs['img'] = img\n",
    "outputs['out'] = out\n",
    "  \n",
    "#Graficamos las imágenes \n",
    "counter = 1\n",
    "val = outputs['out'].detach().numpy()\n",
    "\n",
    "figure = plt.figure(figsize = (20, 10))  \n",
    "# predicción de las 10 primeras imagenes del batch \n",
    "for idx in range(10):\n",
    "    plt.subplot(2, 10, counter)\n",
    "    plt.title(\"Reconstructed \\n image n=64\")\n",
    "    plt.imshow(val[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    counter += 1\n",
    "  \n",
    "  \n",
    "# 10 primeras imágenes originales del batch\n",
    "for idx in range(10):\n",
    "    val = outputs['img']\n",
    "    plt.subplot(2, 10, counter)\n",
    "    plt.imshow(val[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    counter += 1\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.savefig('Img64.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
